import json
from typing import Tuple
import uuid # ç¡®ä¿ uuid è¢«å¯¼å…¥ï¼Œç”¨äºæµå¼å¤„ç†ä¸­çš„ tool_call id ç”Ÿæˆ
import os

from openai import OpenAIError # ç”¨äºæ›´ç²¾ç¡®åœ°æ•è· OpenAI ç›¸å…³å¼‚å¸¸
import requests
from openai import OpenAI
from utils import config
import re
import json
from collections import defaultdict
import time

MODEL = "qwen3-235b-a22b-instruct-2507"
INITIAL_QUESTIONS_COUNT = 8 # åˆå§‹ç”Ÿæˆçš„é—®é¢˜æ•°é‡
MAX_ADDITIONAL_QUESTIONS = 2 # æœ€å¤šå…è®¸é¢å¤–å¢åŠ çš„é—®é¢˜æ•°é‡
PERFORM_VERIFICATION = False # æ˜¯å¦æ‰§è¡ŒéªŒè¯æŠ¥å‘Šçš„ç”Ÿæˆ
SOURCE_DOCUMENTS_DIR = "./africa2024_raw_files/" # æºæ–‡æ¡£æ‰€åœ¨çš„ç›®å½•
QUERY_PROMPT = "ç»™å‡ºå‚è€ƒæ–‡çŒ®æ—¶ï¼Œè¯·å¿ å®ç»™å‡ºåŸæ–‡æ¡£åï¼Œä¸è¦ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¹Ÿä¸è¦æŠŠrelationç­‰è¯¯å½“ä½œæ–‡æ¡£åã€‚"
# TOPIC = "éœ€è¦ä¸€ä¸ªæ ‡é¢˜ä¸ºï¼šâ€œéæ´²ç”Ÿç‰©å®‰å…¨æ€åŠ¿ç ”åˆ¤â€çš„æŠ¥å‘Šã€‚å­—æ•°å¤§çº¦åœ¨2000~3000å­—ã€‚åˆ†ä¸ºä¸‰ä¸ªç« èŠ‚ï¼š1.éæ´²ç”Ÿç‰©å®‰å…¨æ€åŠ¿ 2.éæ´²ç”Ÿç‰©å®‰å…¨é£é™©ç‚¹ 3.å¯¹æˆ‘å›½(ä¸­å›½)åº”å¯¹é£é™©åŠåŠ å¼ºéæ´²å›½é™…åˆä½œçš„å»ºè®®"
# TOPIC = "éœ€è¦ä¸€ä¸ªæ ‡é¢˜ä¸ºï¼šâ€œéæ´²ç”Ÿç‰©å®‰å…¨æ€åŠ¿ç ”åˆ¤â€çš„æŠ¥å‘Šã€‚å‡ ç™¾å­—å³å¯"
TOPIC = '''
Promptï¼šéæ´²ç”Ÿç‰©å®‰å…¨æ€åŠ¿ç ”åˆ¤æŠ¥å‘Šç”ŸæˆæŒ‡ä»¤
è¯·æ’°å†™ä¸€ç¯‡æ™ºåº“ç ”ç©¶æŠ¥å‘Šï¼Œæ ‡é¢˜ä¸ºï¼š
ã€Šéæ´²ç”Ÿç‰©å®‰å…¨æ€åŠ¿ç ”åˆ¤ã€‹
æœ¬æŠ¥å‘Šé¢å‘æ”¿ç­–ç ”ç©¶æœºæ„å†…éƒ¨å‚è€ƒï¼Œä¾›æ”¿åºœéƒ¨é—¨é¢†å¯¼ç ”åˆ¤å†³ç­–ä½¿ç”¨ã€‚å…¨æ–‡å»ºè®®æ§åˆ¶åœ¨ 3000 å­—å·¦å³ï¼Œå†…å®¹è¦æ±‚å¦‚ä¸‹ï¼š
________________________________________
ğŸ“Œ æŠ¥å‘Šç»“æ„ä¸å†…å®¹æŒ‡å¼•
1ï¸âƒ£ éæ´²ç”Ÿç‰©å®‰å…¨æ•´ä½“æ€åŠ¿
â€¢	æ¦‚è¿°éæ´²å½“å‰ç”Ÿç‰©å®‰å…¨å½¢åŠ¿ï¼›
â€¢	å¯åŒ…æ‹¬ä¼ æŸ“ç—…æµè¡Œè¶‹åŠ¿ã€ç”Ÿç‰©é˜²æ§åŸºç¡€èƒ½åŠ›ã€å…³é”®æœºæ„ä½œç”¨ã€å›½é™…åˆä½œæœºåˆ¶ç­‰æ–¹é¢ï¼›
â€¢	å¼•ç”¨ 2024å¹´ 9 æœˆä»¥æ¥çš„æœ€æ–°æ•°æ®æˆ–æ­£å¼æŠ¥å‘Šæ”¯æ’‘åˆ†æã€‚
2ï¸âƒ£ å½“å‰é¢ä¸´çš„ä¸»è¦ç”Ÿç‰©å®‰å…¨é£é™©ä¸æ·±åº¦åˆ†æ
â€¢	æ¢³ç†ä¸»è¦é£é™©ç±»å‹ï¼Œå¹¶æä¾›å®é™…æ¡ˆä¾‹æˆ–æ•°æ®æ”¯æŒï¼›
â€¢	å¼ºè°ƒé£é™©çš„ç³»ç»Ÿæ€§ä¸æŒç»­æ€§ï¼ŒæŒ‡å‡ºçŸ­æœŸå†…éš¾ä»¥ç¼“è§£çš„é—®é¢˜ï¼›
â€¢	åˆ†æé£é™©èƒŒåçš„ç»“æ„æ€§æ ¹æºï¼Œå¯ç»“åˆå…·ä½“å›½å®¶è¿›è¡Œè¯´æ˜ã€‚
3ï¸âƒ£ ä¸­å›½åº”å¯¹ç­–ç•¥ä¸ä¸­éåˆä½œå»ºè®®
â€¢	å»ºè®®åº”ç´§æ‰£å‰è¿°é£é™©ä¸é—®é¢˜ï¼Œå›´ç»•æˆ˜ç•¥å®šä½ã€æœºåˆ¶å»ºè®¾ã€èƒ½åŠ›æå‡ã€å¤šè¾¹ååŒç­‰æ–¹é¢æå‡ºï¼›
â€¢	æ‰€æœ‰å»ºè®®åº”å…·å¤‡ä¸€å®šå¯è¡Œæ€§ä¸é’ˆå¯¹æ€§ï¼›
â€¢	å¯ç»“åˆä¸­å›½ç›¸å…³æ”¿ç­–ç«‹åœºæå‡ºåˆä½œæ–¹å‘å»ºè®®ï¼Œé¿å…æ³›æ³›è€Œè°ˆã€‚
________________________________________
ğŸ“Œ å†™ä½œé£æ ¼ä¸æŠ€æœ¯è§„èŒƒ
â€¢	ä½¿ç”¨æ”¿ç­–ç ”ç©¶é£æ ¼è¯­è¨€ï¼Œç†æ€§ã€ä¸“ä¸šã€é€»è¾‘æ¸…æ™°ï¼›
â€¢	å¼•ç”¨æƒå¨æ•°æ®ä¸æ­£å¼æ–‡ä»¶æ—¶è¯·æ ‡æ³¨æ¥æºä¸æ—¶é—´ï¼›
â€¢	ç¼©ç•¥è¯è¯·åœ¨é¦–æ¬¡å‡ºç°æ—¶æ³¨æ˜å…¨ç§°ï¼›
â€¢	æŠ¥å‘Šåº”é¿å…ç©ºæ³›ï¼Œçªå‡ºé—®é¢˜å¯¼å‘ä¸æ”¿ç­–å»ºè®®çš„é€‚ç”¨æ€§ã€‚
________________________________________
âœ… è¾“å‡ºç›®æ ‡ï¼š
ç”Ÿæˆä¸€ç¯‡é€»è¾‘æ¸…æ™°ã€æ•°æ®å……åˆ†ã€é—®é¢˜å¯¼å‘æ˜ç¡®ã€å»ºè®®å…·æœ‰å¯æ“ä½œæ€§çš„æ™ºåº“ç ”ç©¶æŠ¥å‘Šï¼Œå¯ä¾›æ”¿åºœéƒ¨é—¨é¢†å¯¼ç ”åˆ¤ä½¿ç”¨ã€‚


'''


def post_to_openai_api(messages, model, stream=False, collect_stream=True, tools=None):
    try:
        client = OpenAI(
            api_key=config().django_llm_key,
            base_url=config().django_llm_url
        )
        
        # æ„å»ºAPIè°ƒç”¨å‚æ•°
        api_params = {
            "model": model,
            "messages": messages,
            # "extra_body": {"enable_thinking": True},
            "stream": stream,
        }
        
        # å¦‚æœæä¾›äº†å·¥å…·ï¼Œæ·»åŠ åˆ°APIè°ƒç”¨ä¸­
        if tools:
            api_params["tools"] = tools
            api_params["tool_choice"] = "auto"

        print(f"è°ƒç”¨API: {config().django_llm_url}")
        print(f"æ¨¡å‹: {model}")
        print(f"æ¶ˆæ¯æ•°é‡: {len(messages)}")
        
        completion = client.chat.completions.create(**api_params)
        
    except Exception as api_error:
        print(f"APIè°ƒç”¨é”™è¯¯è¯¦æƒ…: {str(api_error)}")
        print(f"API URL: {config().django_llm_url}")
        print(f"API Key: {config().django_llm_key[:20]}...")
        raise api_error
    
    if stream:
        if collect_stream:
            # æ”¶é›†æ‰€æœ‰æµå¼æ•°æ®å¹¶æ‹¼æ¥
            collected_content = ""
            tool_calls = []
            full_response = None
            
            for chunk in completion:
                if chunk.choices and len(chunk.choices) > 0:
                    choice = chunk.choices[0]
                    delta = choice.delta
                    
                    # æ”¶é›†å†…å®¹
                    if hasattr(delta, 'content') and delta.content:
                        collected_content += delta.content
                    
                    # æ”¶é›†å·¥å…·è°ƒç”¨
                    if hasattr(delta, 'tool_calls') and delta.tool_calls:
                        for tool_call in delta.tool_calls:
                            if tool_call.index >= len(tool_calls):
                                tool_calls.extend([None] * (tool_call.index + 1 - len(tool_calls)))
                            
                            if tool_calls[tool_call.index] is None:
                                tool_calls[tool_call.index] = {
                                    "id": tool_call.id or f"call_{uuid.uuid4().hex[:8]}",
                                    "type": "function",
                                    "function": {
                                        "name": tool_call.function.name or "",
                                        "arguments": tool_call.function.arguments or ""
                                    }
                                }
                            else:
                                # è¿½åŠ å‚æ•°
                                if tool_call.function.arguments:
                                    tool_calls[tool_call.index]["function"]["arguments"] += tool_call.function.arguments
                    
                    # ä¿å­˜æœ€åä¸€ä¸ªchunkä½œä¸ºæ¨¡æ¿
                    full_response = chunk.model_dump()
            
            # æ„å»ºå®Œæ•´å“åº”
            if full_response:
                choice_data = {
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": collected_content if collected_content else None,
                    },
                    "finish_reason": "stop"
                }
                
                # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ·»åŠ åˆ°å“åº”ä¸­
                if tool_calls and any(tc for tc in tool_calls):
                    choice_data["message"]["tool_calls"] = [tc for tc in tool_calls if tc]
                    choice_data["finish_reason"] = "tool_calls"
                
                full_response["choices"] = [choice_data]
                
            return full_response or {
                "choices": [{
                    "index": 0,
                    "message": {
                        "role": "assistant", 
                        "content": collected_content if collected_content else None
                    },
                    "finish_reason": "stop"
                }]
            }
        else:
            # è¿”å›ç”Ÿæˆå™¨å‡½æ•°ç”¨äºæµå¼å“åº”
            def generate():
                for chunk in completion:
                    chunk_data = chunk.model_dump()
                    yield f"data: {json.dumps(chunk_data)}\n\n"
                yield "data: [DONE]\n\n"
            return generate()
    else:
        # éæµå¼å“åº”ï¼Œç›´æ¥è¿”å›å­—å…¸
        return completion.model_dump()

def send_query_to_RAG_server(query: str, mode: str = "naive", url: str = config().lightrag_service_url) -> Tuple[str, str] :
    """å‘RAGæœåŠ¡å™¨å‘é€æŸ¥è¯¢"""
    # POST to url
    # {
    #     "message": "ä½ çš„æŸ¥è¯¢é—®é¢˜",
    #     "mode": "æŸ¥è¯¢æ¨¡å¼"
    # }
    data = {
        "message": query,
        "mode": mode,
        "deep_research": True  # æ ‡æ˜è¿™ä¸ªqueryè¯·æ±‚æ˜¯åœ¨è¿›è¡Œdeep researchçš„è¿‡ç¨‹ä¸­å‘å‡ºçš„ï¼Œè¿™æ ·çš„è¯ragç³»ç»Ÿåœ¨ç”Ÿæˆå†…å®¹æ—¶ï¼Œå°†ä¸ä¼šåœ¨ç»“å°¾å¤„å®Œæ•´åˆ—å‡ºå‚è€ƒæ–‡çŒ®
    }
    response = requests.post(url, json=data)
    return response.json()["result"], response.json()["log_file_path"]


class ResearchAgent:

    def __init__(self, topic, model_name="gpt-4.1-ca", initial_questions=INITIAL_QUESTIONS_COUNT, max_extra_questions=MAX_ADDITIONAL_QUESTIONS):

        self.state = {
            "original_topic": topic,
            "question_list": [],
            "completed_qa_pairs": [],
            "research_log": [], # å¯é€‰ï¼šè®°å½•ç ”ç©¶è¿‡ç¨‹
            "added_questions_count": 0 # è®°å½•é¢å¤–å¢åŠ çš„é—®é¢˜æ•°é‡
        }
        self.model = model_name
        self.initial_questions_count = initial_questions
        self.max_additional_questions = max_extra_questions

    def _call_llm(self, system_prompt, user_prompt, tools=None):
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            response = post_to_openai_api(messages, self.model, stream=False, tools=tools)
            
            content = response['choices'][0]['message'].get('content')
            if content:
                return content.strip()
            else:
                print("è­¦å‘Š: LLMå“åº”ä¸­æ²¡æœ‰å†…å®¹ã€‚")
                return ""
        except (OpenAIError, KeyError, IndexError) as e:
            print(f"è°ƒç”¨LLMæ—¶å‡ºé”™: {e}")
            return "" # æˆ–è€…è¿”å›ä¸€ä¸ªè¡¨ç¤ºå¤±è´¥çš„ç‰¹æ®Šå­—ç¬¦ä¸²

    def _parse_json_from_llm_response(self, response_text):
        if not response_text:
            return []
        try:
            return json.loads(response_text)
        except json.JSONDecodeError:
            start_marker = "```json"
            end_marker = "```"
            start_index = response_text.find(start_marker)
            end_index = response_text.rfind(end_marker)
            
            if start_index != -1 and end_index != -1 and start_index < end_index:
                json_str = response_text[start_index + len(start_marker):end_index].strip()
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError:
                    print(f"æ— æ³•è§£æJSONä»£ç å—: {json_str}")
                    return []
            else:
                print(f"LLMå“åº”æ ¼å¼ä¸æ­£ç¡®ï¼Œæ— æ³•æ‰¾åˆ°JSONæ•°ç»„: {response_text}")
                return []

    def plan_research(self):
        print("--- é˜¶æ®µä¸€ï¼šè§„åˆ’ç ”ç©¶ ---")
        system_prompt = (
            "ä½ æ˜¯ä¸€ä½èµ„æ·±è¡Œä¸šç ”ç©¶å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†å¤æ‚çš„ç ”ç©¶ä¸»é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—å…·ä½“ã€æ¸…æ™°ã€å¯ç‹¬ç«‹å›ç­”çš„é—®é¢˜ã€‚"
            "è¿™äº›é—®é¢˜å°†ç”¨äºä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯ã€‚"
        )
        user_prompt = (
            f"ç ”ç©¶ä¸»é¢˜æ˜¯ï¼š{self.state['original_topic']}\n\n"
            f"è¯·è®¾è®¡ä¸€ä¸ªå…¨é¢çš„ç ”ç©¶å¤§çº²ï¼Œå¹¶å°†å…¶åˆ†è§£ä¸º {self.initial_questions_count} ä¸ªæ ¸å¿ƒé—®é¢˜ã€‚"
            "é—®é¢˜åº”è¦†ç›–ä¸»é¢˜çš„å„ä¸ªæ–¹é¢ï¼Œé€»è¾‘æ¸…æ™°ï¼Œè¡¨è¿°æ˜ç¡®ã€‚"
            "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼šä¸€ä¸ªåŒ…å«é—®é¢˜çš„JSONæ•°ç»„ï¼Œä¸è¦æœ‰å…¶ä»–ä»»ä½•æ–‡å­—æˆ–è§£é‡Šã€‚"
            "ä¾‹å¦‚: [\"é—®é¢˜1ï¼Ÿ\", \"é—®é¢˜2ï¼Ÿ\", ...]"
        )

        response_text = self._call_llm(system_prompt, user_prompt)
        question_list = self._parse_json_from_llm_response(response_text)

        if not question_list:
            print("è­¦å‘Šï¼šæœªèƒ½ä»LLMè·å–æœ‰æ•ˆçš„åˆå§‹é—®é¢˜åˆ—è¡¨ã€‚ç ”ç©¶å¯èƒ½æ— æ³•ç»§ç»­ã€‚")
            exit()
            question_list = [f"å…³äº{self.state['original_topic']}çš„å…³é”®é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ"]

        self.state['question_list'] = question_list
        print(f"å·²ç”Ÿæˆåˆå§‹é—®é¢˜åˆ—è¡¨ ({len(question_list)} ä¸ªé—®é¢˜)ã€‚")

    def execute_and_reflect(self):
        print("\n--- é˜¶æ®µäºŒï¼šè¿­ä»£ç ”ç©¶ä¸åæ€ ---")
        iteration = 1
        while self.state['question_list']:
            print(f"\n--- è¿­ä»£ {iteration} ---")
            current_question = self.state['question_list'].pop(0) # å–å‡ºç¬¬ä¸€ä¸ªé—®é¢˜
            print(f"æ­£åœ¨ç ”ç©¶é—®é¢˜: {current_question}")

            try:
                rag_answer, log_file_path = send_query_to_RAG_server(QUERY_PROMPT + current_question, mode="naive")
                print(f"RAGå›ç­”: {rag_answer[:100]}...") # æ‰“å°éƒ¨åˆ†å›ç­”ä½œä¸ºåé¦ˆ
            except Exception as e:
                print(f"è°ƒç”¨RAGæœåŠ¡æ—¶å‡ºé”™: {e}")
                rag_answer = "æœªèƒ½ä»çŸ¥è¯†åº“è·å–ç›¸å…³ä¿¡æ¯ã€‚" # é»˜è®¤å›ç­”

            self.state['completed_qa_pairs'].append({
                "question": current_question,
                "answer": rag_answer,
                "log_path": log_file_path
            })

            system_prompt = (
                "ä½ æ˜¯ä¸€ä½ç ”ç©¶ç­–ç•¥å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®å·²æ”¶é›†çš„ä¿¡æ¯ï¼ŒåŠ¨æ€ä¼˜åŒ–åç»­çš„ç ”ç©¶è®¡åˆ’ã€‚"
                "ä½ éœ€è¦å®¡è§†å½“å‰çš„é—®é¢˜åˆ—è¡¨ï¼Œå¹¶æ ¹æ®æ–°è·å¾—çš„çŸ¥è¯†å¯¹å…¶è¿›è¡Œä¿®æ”¹ã€æ·»åŠ æˆ–åˆ é™¤ã€‚"
            )
            
            formatted_qa = "\n".join([f"Q: {pair['question']}\nA: {pair['answer']}\n" for pair in self.state['completed_qa_pairs']])
            formatted_todo = "\n".join([f"{i+1}. {q}" for i, q in enumerate(self.state['question_list'])])

            remaining_allowed = self.max_additional_questions - self.state['added_questions_count']
            user_prompt = (
                f"åŸå§‹ç ”ç©¶ä¸»é¢˜: {self.state['original_topic']}\n\n"
                f"æˆ‘ä»¬å·²ç»å®Œæˆçš„ç ”ç©¶é—®ç­”:\n{formatted_qa}\n\n"
                f"æˆ‘ä»¬æ¥ä¸‹æ¥è®¡åˆ’ç ”ç©¶çš„é—®é¢˜åˆ—è¡¨:\n{formatted_todo}\n\n"
                "è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œå¯¹å‰©ä½™çš„é—®é¢˜åˆ—è¡¨è¿›è¡Œä¼˜åŒ–ã€‚\n"
                "ä½ å¯ä»¥ï¼š\n"
                "1. ä¿®æ”¹ç°æœ‰é—®é¢˜ï¼Œä½¿å…¶æ›´æ·±å…¥æˆ–æ›´å‡†ç¡®ã€‚\n"
                "2. æ·»åŠ ç”±æ–°ä¿¡æ¯å¯å‘çš„æ–°é—®é¢˜ã€‚\n"
                "3. åˆ é™¤å·²ç»è§£ç­”æˆ–ä¸å†ç›¸å…³çš„é—®é¢˜ã€‚\n"
                f"æ³¨æ„ï¼šä½ æœ€å¤šè¿˜å¯ä»¥æ·»åŠ  {remaining_allowed} ä¸ªæ–°é—®é¢˜ã€‚\n"
                "ç¡®ä¿æœ€ç»ˆé—®é¢˜åˆ—è¡¨é€»è¾‘è¿è´¯ã€æ— é‡å¤ï¼Œå¹¶èƒ½æ”¯æ’‘ä¸€ä»½å®Œæ•´çš„æŠ¥å‘Šã€‚\n"
                "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼šä¸€ä¸ªåŒ…å«æ›´æ–°åé—®é¢˜çš„JSONæ•°ç»„ï¼Œä¸è¦æœ‰å…¶ä»–ä»»ä½•æ–‡å­—æˆ–è§£é‡Šã€‚"
                "ä¾‹å¦‚: [\"ä¿®æ”¹åçš„é—®é¢˜1ï¼Ÿ\", \"æ–°é—®é¢˜ï¼Ÿ\", ...]"
            )

            response_text = self._call_llm(system_prompt, user_prompt)
            updated_question_list = self._parse_json_from_llm_response(response_text)

            if updated_question_list is not None: # å³ä½¿æ˜¯ç©ºåˆ—è¡¨ä¹Ÿæ˜¯æœ‰æ•ˆçš„æ›´æ–°
                # é™åˆ¶å¯ä»¥æ·»åŠ çš„æ–°é—®é¢˜æ•°é‡
                questions_before_reflection = len(self.state['question_list'])
                newly_added_count = len(updated_question_list) - questions_before_reflection

                if newly_added_count > 0:
                    if self.state['added_questions_count'] >= self.max_additional_questions:
                        print(f"è­¦å‘Šï¼šå·²è¾¾åˆ°é¢å¤–é—®é¢˜ä¸Šé™({self.max_additional_questions})ï¼Œæ–°é—®é¢˜å°†è¢«å¿½ç•¥ã€‚")
                        updated_question_list = updated_question_list[:questions_before_reflection]
                    else:
                        allowed_new = self.max_additional_questions - self.state['added_questions_count']
                        if newly_added_count > allowed_new:
                            print(f"è­¦å‘Šï¼šæœ¬æ¬¡æ–°å¢é—®é¢˜è¿‡å¤šï¼Œåªä¿ç•™ {allowed_new} ä¸ªã€‚")
                            updated_question_list = updated_question_list[:questions_before_reflection + allowed_new]
                            self.state['added_questions_count'] = self.max_additional_questions
                        else:
                            self.state['added_questions_count'] += newly_added_count
                
                print(f"åæ€åï¼Œé—®é¢˜åˆ—è¡¨å·²æ›´æ–° (å‰©ä½™ {len(updated_question_list)} ä¸ªé—®é¢˜)ã€‚")
                self.state['question_list'] = updated_question_list
            else:
                print("è­¦å‘Šï¼šåæ€é˜¶æ®µæœªèƒ½è·å–æœ‰æ•ˆçš„æ›´æ–°åé—®é¢˜åˆ—è¡¨ï¼Œå°†ä¿ç•™å½“å‰åˆ—è¡¨ã€‚")
            
            iteration += 1

        print("\n--- é˜¶æ®µäºŒå®Œæˆï¼šæ‰€æœ‰é—®é¢˜å‡å·²ç ”ç©¶å®Œæ¯•ã€‚---")

    def synthesize_report(self):
        print("\n--- é˜¶æ®µä¸‰ï¼šç»¼åˆç”ŸæˆæŠ¥å‘Š ---")
        if not self.state['completed_qa_pairs']:
            print("æ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•ä¿¡æ¯ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚")
            return "æ— æ³•ç”ŸæˆæŠ¥å‘Šï¼šæœªæ”¶é›†åˆ°ä»»ä½•ä¿¡æ¯ã€‚"

        system_prompt = (
            "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æŠ¥å‘Šæ’°å†™ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„åŸå§‹ä¸»é¢˜å’Œä¸€ç³»åˆ—é—®ç­”å¯¹ï¼Œæ’°å†™ä¸€ä»½ç»“æ„æ¸…æ™°ã€é€»è¾‘ä¸¥è°¨ã€å†…å®¹è¯¦å®çš„æœ€ç»ˆç ”ç©¶æŠ¥å‘Šã€‚"
        )
        
        # æ ¼å¼åŒ–æ‰€æœ‰QAå¯¹ä½œä¸ºæŠ¥å‘Šç´ æ
        formatted_qa = "\n\n".join([
            f"**é—®é¢˜ {i+1}:** {pair['question']}\n\n**å›ç­”:** {pair['answer']}" 
            for i, pair in enumerate(self.state['completed_qa_pairs'])
        ])

        user_prompt = (
            f"åŸå§‹ç ”ç©¶ä¸»é¢˜: {self.state['original_topic']}\n\n"
            f"æ ¹æ®ä»¥ä¸‹ç ”ç©¶èµ„æ–™æ’°å†™æŠ¥å‘Šï¼š\n\n{formatted_qa}\n\n"
            "è¦æ±‚ï¼š\n"
            "1. æŠ¥å‘Šåº”åŒ…å«å¼•è¨€ã€ä¸»ä½“å’Œç»“è®ºã€‚\n"
            "2. ä¸»ä½“éƒ¨åˆ†åº”é€»è¾‘æ¸…æ™°åœ°ç»„ç»‡ä¿¡æ¯ï¼Œå¯ä»¥åˆ†ç« èŠ‚ã€‚\n"
            "3. è¯­è¨€æµç•…ã€ä¸“ä¸šã€‚\n"
            "4. ç›´æ¥è¾“å‡ºæŠ¥å‘Šæ­£æ–‡ï¼Œæ— éœ€é¢å¤–è¯´æ˜ã€‚\n"
            "5. æ¯ä¸ªå¤§ç« èŠ‚ä¸‹é¢å»ºè®®å¸ƒç½®2~4ä¸ªå°èŠ‚ï¼Œè§†ä¿¡æ¯ä¸°å¯Œç¨‹åº¦è€Œå®šã€‚\n"
            "6. æ¯ä¸ªå°èŠ‚çš„ä¸»ä½“æ˜¯1~2æ®µå†…å®¹ä¸°å¯Œã€è¯­è¨€è¿ç»­çš„æ®µè½ï¼Œè¯·ä¸è¦å¤§é‡åˆ†ç‚¹ã€‚\n"
            "7. å°½é‡å¤šå‡ºç°ä¸€äº›å’Œæ—¶é—´æœ‰å…³çš„å™è¿°ï¼Œç”¨ä»¥æå‡æŠ¥å‘Šçš„æ—¶æ•ˆæ€§ã€‚ä¾‹å¦‚xxxxå¹´xxæœˆè¿™ç§ã€‚\n"
            "8. åœ¨å¥å­åæ ‡æ³¨å¼•ç”¨æ¥è‡ªå“ªä¸ªé—®é¢˜çš„å›å¤ã€‚å¦‚ï¼Œå¦‚æœæ˜¯æ¥è‡ªé—®é¢˜1çš„å›å¤ä¸­çš„[DC #16]ï¼Œé‚£ä¹ˆå°±åœ¨å¥å­åé¢æ ‡æ³¨[Q #1, DC #16]ã€‚å¦‚æœæœ‰å¤šä¸ªæ¥æºï¼Œå¯ä»¥å†™æˆ[Q #1, DC #4-6 #15 #17]è¿™ç§ã€‚å¦‚æœä¸€ä¸ªå¥å­æ¶‰åŠåˆ°ä¸¤ä¸ªåŠä»¥ä¸Šçš„é—®é¢˜çš„å›å¤ï¼Œä¾‹å¦‚åŒæ—¶æ¶‰åŠåˆ°äº†ç¬¬ä¸€ä¸ªé—®é¢˜çš„å›å¤å’Œç¬¬äºŒä¸ªé—®é¢˜çš„å›å¤ï¼Œé‚£ä¹ˆå¯ä»¥å†™æˆ[Q #1, DC #3; Q #2, DC #3 #5]è¿™ç§ã€‚Qçš„åé¢å¿…é¡»å¸¦æœ‰DCï¼Œç¦æ­¢å‡ºç°[Q #x] [Q #8; DC #3 #7 #10]è¿™ç§åªæœ‰é—®é¢˜ç¼–å·å´æ— å®é™…å†…å®¹æˆ–è€…åªæœ‰å†…å®¹æ²¡æœ‰é—®é¢˜ç¼–å·çš„æ ‡æ³¨ã€‚"
        )

        final_report = self._call_llm(system_prompt, user_prompt)
        print("\n--- é˜¶æ®µä¸‰å®Œæˆï¼šæŠ¥å‘Šå·²ç”Ÿæˆã€‚---")
        return final_report

    def _post_process_report_and_add_references(self, raw_report, references_map):
        """
        åå¤„ç†æŠ¥å‘Šï¼šå°†å¼•ç”¨æ ‡è®°è½¬æ¢ä¸ºæ•°å­—åºå·ï¼Œå¹¶ç”Ÿæˆå‚è€ƒæ–‡çŒ®åˆ—è¡¨
        """
        print("\n--- å¼€å§‹åå¤„ç†æŠ¥å‘Šï¼šè½¬æ¢å¼•ç”¨æ ¼å¼å’Œç”Ÿæˆå‚è€ƒæ–‡çŒ® ---")
        
        # åˆå§‹åŒ–
        # references_map = {}  # æ–‡æ¡£å -> å¼•ç”¨åºå·
        citation_counter = 1
        question_log_data = {}  # é—®é¢˜åºå· -> æ—¥å¿—JSONæ•°æ®
        
        # é¢„åŠ è½½æ‰€æœ‰æ—¥å¿—æ•°æ®
        for i, qa_pair in enumerate(self.state['completed_qa_pairs']):
            question_num = i + 1  # é—®é¢˜åºå·ä»1å¼€å§‹
            log_path = qa_pair.get('log_path')
            
            if log_path:
                try:
                    with open(log_path, 'r', encoding='utf-8') as f:
                        question_log_data[question_num] = json.load(f)
                    print(f"å·²åŠ è½½é—®é¢˜ {question_num} çš„æ—¥å¿—æ•°æ®")
                except (FileNotFoundError, json.JSONDecodeError, Exception) as e:
                    print(f"è­¦å‘Šï¼šæ— æ³•è¯»å–é—®é¢˜ {question_num} çš„æ—¥å¿—æ–‡ä»¶ {log_path}: {e}")
                    question_log_data[question_num] = None
        
        def extract_file_paths_from_citation(citation_match):
            """è§£æå•ä¸ªå¼•ç”¨æ ‡è®°å¹¶è¿”å›å¯¹åº”çš„æ–‡æ¡£ååˆ—è¡¨"""
            citation_text = citation_match.group(0)  # å®Œæ•´çš„åŒ¹é…æ–‡æœ¬ï¼Œå¦‚ [Q #1, E #16, R #15]
            
            try:
                # ç§»é™¤æ–¹æ‹¬å·
                inner_text = citation_text[1:-1]  # å»æ‰ [ å’Œ ]
                
                # æŒ‰åˆ†å·åˆ†å‰²ä¸åŒçš„é—®é¢˜ç»„ï¼Œå¦‚ "Q #1, R #3; Q #2, R #3 #5"
                question_groups = [group.strip() for group in inner_text.split(';')]
                
                all_file_paths = set()  # ä½¿ç”¨setå»é‡
                
                for group in question_groups:
                    # è§£ææ¯ä¸ªé—®é¢˜ç»„ï¼Œå¦‚ "Q #1, E #16, R #15"
                    parts = [part.strip() for part in group.split(',')]
                    
                    current_question = None
                    for part in parts:
                        if part.startswith('Q #'):
                            # æå–é—®é¢˜åºå·
                            current_question = int(part.replace('Q #', ''))
                        elif current_question and current_question in question_log_data:
                            # å¤„ç†å®ä½“/å…³ç³»/æ–‡æœ¬å•å…ƒå¼•ç”¨
                            log_data = question_log_data[current_question]
                            if log_data:
                                file_paths = self._extract_file_paths_from_part(part, log_data)
                                all_file_paths.update(file_paths)
                
                return list(all_file_paths)
                
            except Exception as e:
                print(f"è­¦å‘Šï¼šè§£æå¼•ç”¨æ ‡è®° {citation_text} æ—¶å‡ºé”™: {e}")
                return []
        
        def replace_citation(match):
            """æ›¿æ¢å‡½æ•°ï¼šå°†æ—§å¼•ç”¨æ ¼å¼è½¬æ¢ä¸ºæ–°çš„æ•°å­—æ ¼å¼"""
            nonlocal citation_counter
            
            # è·å–å½“å‰å¼•ç”¨å¯¹åº”çš„æ‰€æœ‰æ–‡æ¡£å
            file_paths = extract_file_paths_from_citation(match)
            
            # ä¸ºæ¯ä¸ªæ–‡æ¡£ååˆ†é…åºå·
            citation_numbers = []
            for file_path in sorted(set(file_paths)):  # å»é‡å¹¶æ’åº
                if file_path not in references_map:
                    references_map[file_path] = citation_counter
                    citation_counter += 1
                citation_numbers.append(references_map[file_path])
            
            # ç”Ÿæˆæ–°çš„å¼•ç”¨æ ¼å¼
            if citation_numbers:
                citation_numbers.sort()
                if len(citation_numbers) == 1:
                    return f"[{citation_numbers[0]}]"
                else:
                    return f"[{', '.join(map(str, citation_numbers))}]"
            else:
                return match.group(0)  # å¦‚æœæ— æ³•è§£æï¼Œä¿æŒåŸæ ·
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾å’Œæ›¿æ¢æ‰€æœ‰å¼•ç”¨æ ‡è®°
        citation_pattern = r'\[Q #[^\]]+\]'
        processed_report = re.sub(citation_pattern, replace_citation, raw_report)
        
        # ç”Ÿæˆå‚è€ƒæ–‡çŒ®åˆ—è¡¨
        if references_map:
            # æŒ‰åºå·æ’åº
            sorted_references = sorted(references_map.items(), key=lambda x: x[1])
            
            references_section = "\n\n## å‚è€ƒæ–‡çŒ®\n\n"
            for doc_name, ref_num in sorted_references:
                references_section += f"[{ref_num}] {doc_name}\n"
            
            processed_report += references_section
            print(f"å·²ç”Ÿæˆ {len(references_map)} ä¸ªå‚è€ƒæ–‡çŒ®")
        
        return processed_report
    
    def _extract_file_paths_from_part(self, part, log_data):
        """ä»å¼•ç”¨éƒ¨åˆ†æå–æ–‡æ¡£è·¯å¾„"""
        file_paths = set()
        
        try:
            if part.startswith('E #'):
                # å¤„ç†å®ä½“å¼•ç”¨ï¼Œå¦‚ "E #16" æˆ– "E #14-16"
                ids = self._parse_id_range(part.replace('E #', ''))
                entities = log_data.get('entities', [])
                for entity in entities:
                    if str(entity.get('id', '')) in ids:
                        file_path = entity.get('file_path')
                        if file_path:
                            file_paths.update(path.strip() for path in file_path.split(';') if path.strip())
            
            elif part.startswith('R #'):
                # å¤„ç†å…³ç³»å¼•ç”¨ï¼Œå¦‚ "R #15" æˆ– "R #15 #17"  
                ids = self._parse_id_list(part.replace('R #', ''))
                relations = log_data.get('relations', [])
                for relation in relations:
                    if str(relation.get('id', '')) in ids:
                        file_path = relation.get('file_path')
                        if file_path:
                            file_paths.update(path.strip() for path in file_path.split(';') if path.strip())
            
            elif part.startswith('DC #'):
                # å¤„ç†æ–‡æœ¬å•å…ƒå¼•ç”¨
                ids = self._parse_id_list(part.replace('DC #', ''))
                text_units = log_data.get('text_units', [])
                for text_unit in text_units:
                    if str(text_unit.get('id', '')) in ids:
                        file_path = text_unit.get('file_path')
                        if file_path:
                            file_paths.update(path.strip() for path in file_path.split(';') if path.strip())
        
        except Exception as e:
            print(f"è­¦å‘Šï¼šè§£æå¼•ç”¨éƒ¨åˆ† {part} æ—¶å‡ºé”™: {e}")
        
        return file_paths
    
    def _parse_id_range(self, id_str):
        """è§£æIDèŒƒå›´ï¼Œå¦‚ '14-16' -> ['14', '15', '16']"""
        ids = set()
        if '-' in id_str:
            try:
                start, end = map(int, id_str.split('-'))
                ids.update(str(i) for i in range(start, end + 1))
            except ValueError:
                ids.add(id_str)
        else:
            ids.add(id_str)
        return ids
    
    def _parse_id_list(self, id_str):
        """è§£æIDåˆ—è¡¨ï¼Œå¦‚ '15 #17' -> ['15', '17']"""
        # ç§»é™¤æ‰€æœ‰ # ç¬¦å·å¹¶æŒ‰ç©ºæ ¼åˆ†å‰²
        cleaned = id_str.replace('#', '')
        return set(cleaned.split())

    def verify_report(self, report_text):
        """
        éªŒè¯æŠ¥å‘Šä¸­çš„å¼•ç”¨æ˜¯å¦ä¸åŸæ–‡ç›¸ç¬¦ã€‚

        Args:
            report_text (str): å®Œæ•´çš„æŠ¥å‘Šæ–‡æœ¬ã€‚

        Returns:
            str: éªŒè¯ç»“æœæŠ¥å‘Šã€‚
        """
        print("\n--- é˜¶æ®µå››ï¼šéªŒè¯æŠ¥å‘Šå†…å®¹ ---")

        # 1. è§£ææŠ¥å‘Šï¼Œæå–æ­£æ–‡å’Œå¼•ç”¨
        # å‡è®¾æŠ¥å‘Šç»“æ„æ˜¯ï¼šä¸»é¢˜ã€æ­£æ–‡ã€å‚è€ƒæ–‡çŒ®
        try:
            # ç§»é™¤ä¸»é¢˜å’Œå‚è€ƒæ–‡çŒ®ï¼Œåªä¿ç•™æ­£æ–‡
            body_text = report_text.split("\n\n## å‚è€ƒæ–‡çŒ®\n\n")[0]
            if self.state['original_topic'] in body_text:
                body_text = body_text.replace(f"ç ”ç©¶ä¸»é¢˜ï¼š{self.state['original_topic']}\n\n", "")

            # æå–æ‰€æœ‰å¼•ç”¨æ ‡è®°åŠå…¶æ‰€åœ¨æ®µè½
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾æ‰€æœ‰å¸¦å¼•ç”¨çš„æ®µè½
            # ä¸€ä¸ªæ®µè½è¢«å®šä¹‰ä¸ºè¢«æ¢è¡Œç¬¦åŒ…å›´çš„æ–‡æœ¬å—
            paragraphs = [p.strip() for p in body_text.split('\n\n') if p.strip()]
            citations = defaultdict(list)
            citation_pattern = r'\[(\d+(?:,\s*\d+)*)\]'

            for para in paragraphs:
                matches = re.findall(citation_pattern, para)
                if matches:
                    # æ¸…ç†æ®µè½ï¼Œç§»é™¤å¼•ç”¨æ ‡è®°ï¼Œä»¥ä¾¿å‘é€ç»™LLM
                    cleaned_para = re.sub(citation_pattern, '', para).strip()
                    for match in matches:
                        # ä¸€ä¸ªå¼•ç”¨æ ‡è®°å¯èƒ½åŒ…å«å¤šä¸ªæ•°å­—ï¼Œä¾‹å¦‚ [1, 2]
                        ref_numbers = [int(n.strip()) for n in match.split(',')]
                        for ref_num in ref_numbers:
                            citations[ref_num].append(cleaned_para)

        except Exception as e:
            return f"è§£ææŠ¥å‘Šæ—¶å‡ºé”™: {e}"

        # 2. æ„å»ºéªŒè¯ä»»åŠ¡å¹¶è°ƒç”¨LLM
        verification_results = []
        # åè½¬ references_map ä»¥ä¾¿é€šè¿‡å¼•ç”¨åºå·æŸ¥æ‰¾æ–‡æ¡£å
        ref_map = {v: k for k, v in self.references_map.items()}

        for ref_num, paras in citations.items():
            doc_name = ref_map.get(ref_num)
            if not doc_name:
                verification_results.append({
                    "document": f"æ–‡æ¡£åºå· {ref_num}",
                    "status": "æ— æ³•æ‰¾åˆ°æºæ–‡æ¡£",
                    "details": "",
                    "paragraphs": paras
                })
                continue

            # ä»æŒ‡å®šç›®å½•è¯»å–æºæ–‡æ¡£å†…å®¹
            source_content = f"æ— æ³•åŠ è½½æºæ–‡æ¡£ '{doc_name}' çš„å†…å®¹ã€‚"
            try:
                # ç¡®ä¿æ–‡ä»¶åå®‰å…¨ï¼Œé˜²æ­¢ç›®å½•éå†æ”»å‡»
                safe_doc_name = os.path.basename(doc_name)
                doc_path = os.path.join(SOURCE_DOCUMENTS_DIR, safe_doc_name + '.txt')
                
                if os.path.exists(doc_path):
                    with open(doc_path, 'r', encoding='utf-8') as f:
                        source_content = f.read()
                else:
                    print(f"è­¦å‘Š: æºæ–‡ä»¶æœªæ‰¾åˆ°: {doc_path}")
                    verification_results.append({
                        "document": doc_name,
                        "status": "æºæ–‡ä»¶æœªæ‰¾åˆ°",
                        "path": doc_path,
                        "details": f"å°è¯•å®šä½çš„æºæ–‡æ¡£æœªæ‰¾åˆ°: {doc_path}",
                        "paragraphs": paras
                    })
                    continue

            except Exception as e:
                print(f"è¯»å–æºæ–‡ä»¶ {doc_name} æ—¶å‡ºé”™: {e}")


            system_prompt = (
                "ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„äº‹å®æ ¸æŸ¥å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ¤æ–­æ‰€æä¾›çš„æ®µè½å†…å®¹æ˜¯å¦ä¸æºæ–‡æ¡£å†…å®¹ä¸€è‡´ã€‚"
                "è¯·ä»”ç»†é˜…è¯»æºæ–‡æ¡£å’Œæ®µè½ï¼Œç„¶åç»™å‡ºä½ çš„åˆ¤æ–­ã€‚"
                "åˆ¤æ–­ç»“æœå¿…é¡»æ˜¯ä»¥ä¸‹ä¸‰ç§ä¹‹ä¸€ï¼šTrueï¼ˆç¬¦åˆäº‹å®ï¼‰ã€Falseï¼ˆè¿åäº‹å®ï¼‰ã€Irrelevantï¼ˆä¸ç›¸å…³ï¼‰ã€‚"
                "ä¸è¦è¿”å›ä»»ä½•å…¶ä»–å¤šä½™çš„æ–‡å­—æˆ–è§£é‡Šã€‚"
            )
            joined_paras = '\n\n'.join(paras)
            user_prompt = (
                f"æºæ–‡æ¡£å†…å®¹:\n--- --- --- --- ---\n{source_content}\n--- --- --- --- ---\n\n"
                f"å¾…éªŒè¯æ®µè½:\n--- --- --- --- ---\n{joined_paras}\n--- --- --- --- ---"
            )

            retry_count = 0
            while retry_count < 3:
                response = self._call_llm(system_prompt, user_prompt)
                if response in ["True", "False", "Irrelevant"]:
                    status = response
                    details = ""
                    if status in ["False", "Irrelevant"]:
                        # è¿½é—®åŸå› 
                        reason_prompt_system = "ä½ æ˜¯ä¸€ä½æ·±å…¥çš„åˆ†æå¸ˆã€‚è¯·è§£é‡Šä¸ºä»€ä¹ˆå‰é¢çš„æ®µè½è¢«åˆ¤æ–­ä¸ºè¿åäº‹å®æˆ–ä¸ç›¸å…³ã€‚è¯·æä¾›å…·ä½“ç†ç”±ã€‚"
                        reason_prompt_user = (
                            f"æºæ–‡æ¡£å†…å®¹:\n{source_content}\n\n"
                            f"æ®µè½:\n{joined_paras}\n\n"
                            f"åˆ¤æ–­ç»“æœ: {status}"
                        )
                        details = self._call_llm(reason_prompt_system, reason_prompt_user)
                    
                    verification_results.append({
                        "document": doc_name,
                        "status": status,
                        "paragraphs": paras,
                        "details": details
                    })
                    break
                else:
                    retry_count += 1
            
            if retry_count == 3:
                verification_results.append({
                    "document": doc_name,
                    "status": "æ¨¡å‹æ— æ³•åˆ¤æ–­",
                    "paragraphs": paras,
                    "details": f"æ¨¡å‹åœ¨3æ¬¡å°è¯•åä»æœªè¿”å›æœ‰æ•ˆç»“æœã€‚æœ€åä¸€æ¬¡è¿”å›å€¼ä¸º: {response}"
                })

        # 3. ç”Ÿæˆå¹¶ä¿å­˜éªŒè¯æŠ¥å‘Š
        report = "# ç ”ç©¶æŠ¥å‘Šå†…å®¹éªŒè¯ç»“æœ\n\n"
        issues = [res for res in verification_results if res['status'] != 'True']

        if not issues:
            report += "æ‰€æœ‰å†…å®¹å‡å·²é€šè¿‡éªŒè¯ï¼Œæœªå‘ç°é—®é¢˜ã€‚\n"
        else:
            report += f"å…±å‘ç° {len(issues)} ä¸ªé—®é¢˜ã€‚\n\n"
            for issue in issues:
                if issue['status'] in ["æºæ–‡ä»¶æœªæ‰¾åˆ°", "æ— æ³•æ‰¾åˆ°æºæ–‡æ¡£"]:
                    report += f"## æœªæ‰¾åˆ°æºæ–‡æ¡£: {issue['document']}\n"
                    if issue.get('path'):
                        report += f"- **å°è¯•å®šä½è·¯å¾„**: {issue['path']}\n"
                    if issue.get('details'):
                        report += f"- **è¯¦æƒ…**: {issue['details']}\n"
                    report += "- **ç›¸å…³æ®µè½**:\n"
                    for para in issue['paragraphs']:
                        report += f"  - {para}\n"
                    report += "\n"
                else:
                    report += f"## æ–‡æ¡£: {issue['document']}\n"
                    report += f"- **çŠ¶æ€**: {issue['status']}\n"
                    if issue['details']:
                        report += f"- **è¯¦æƒ…**: {issue['details']}\n"
                    report += "- **ç›¸å…³æ®µè½**:\n"
                    for para in issue['paragraphs']:
                        report += f"  - {para}\n"
                    report += "\n"
        
        return report

    def run(self):
        print(f"å¼€å§‹é’ˆå¯¹ '{self.state['original_topic']}' è¿›è¡Œç ”ç©¶...")
        self.plan_research()
        self.execute_and_reflect()
        raw_report = self.synthesize_report()
        
        # åœ¨ç”ŸæˆåŸå§‹æŠ¥å‘Šåï¼Œè¿›è¡Œåå¤„ç†ä»¥æ·»åŠ å¼•ç”¨
        self.references_map = {} # åˆå§‹åŒ–å¼•ç”¨æ˜ å°„
        processed_report = self._post_process_report_and_add_references(raw_report, self.references_map)
        
        if PERFORM_VERIFICATION:
            # éªŒè¯æŠ¥å‘Šå†…å®¹
            verification_report = self.verify_report(processed_report)
            
            # å°†éªŒè¯æŠ¥å‘Šä¿å­˜åˆ°æ–‡ä»¶
            try:
                timestamp = time.time()
                verification_filename = f"verification_report_{timestamp}.md"
                with open(verification_filename, 'w', encoding='utf-8') as f:
                    f.write(verification_report)
                print(f"\n--- éªŒè¯æŠ¥å‘Šå·²æˆåŠŸä¿å­˜è‡³æ–‡ä»¶: {verification_filename} ---")
            except IOError as e:
                print(f"é”™è¯¯ï¼šæ— æ³•å°†éªŒè¯æŠ¥å‘Šå†™å…¥æ–‡ä»¶ {verification_filename}ã€‚é”™è¯¯ä¿¡æ¯: {e}")

        return raw_report, processed_report

if __name__ == "__main__":
    
    topic = TOPIC
    # ä½¿ç”¨äº†æ–°çš„å‚æ•°æ¥åˆå§‹åŒ– ResearchAgent
    agent = ResearchAgent(
        topic=topic, 
        model_name=MODEL,
        initial_questions=INITIAL_QUESTIONS_COUNT,
        max_extra_questions=MAX_ADDITIONAL_QUESTIONS
    )
    
    try:
        raw_report, report = agent.run()
        print("\n\n========== æœ€ç»ˆç ”ç©¶æŠ¥å‘Š ==========\n")
        print(report)

        # å°†æŠ¥å‘Šä¿å­˜åˆ°æ–‡ä»¶ä¸­
        timestamp = time.time()
        timestamp_str = str(timestamp)
        report_filename = f"research_report_{timestamp_str}.txt"
        raw_report_filename = f"raw_research_report_{timestamp_str}.txt"
        try:
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write(f"ç ”ç©¶ä¸»é¢˜ï¼š{topic}\n\n")
                f.write(report)
            print(f"\n--- æŠ¥å‘Šå·²æˆåŠŸä¿å­˜è‡³æ–‡ä»¶: {report_filename} ---")
        except IOError as e:
            print(f"é”™è¯¯ï¼šæ— æ³•å°†æŠ¥å‘Šå†™å…¥æ–‡ä»¶ {report_filename}ã€‚é”™è¯¯ä¿¡æ¯: {e}")
        try:
            with open(raw_report_filename, 'w', encoding='utf-8') as f:
                f.write(f"ç ”ç©¶ä¸»é¢˜ï¼š{topic}\n\n")
                f.write(raw_report)
            print(f"\n--- åŸå§‹æŠ¥å‘Šå·²æˆåŠŸä¿å­˜è‡³æ–‡ä»¶: {raw_report_filename} ---")
        except IOError as e:
            print(f"é”™è¯¯ï¼šæ— æ³•å°†æŠ¥å‘Šå†™å…¥æ–‡ä»¶ {raw_report_filename}ã€‚é”™è¯¯ä¿¡æ¯: {e}")

    except Exception as e:
        print(f"ç ”ç©¶æµç¨‹æ‰§è¡Œå‡ºé”™: {e}")

